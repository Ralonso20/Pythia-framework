"""
Azure Service Bus Benchmark using Azure Service Bus Emulator (Azurite)
"""

import asyncio
import time
import json
import uuid
from typing import List, Tuple
from azure.servicebus.aio import ServiceBusClient, ServiceBusSender, ServiceBusReceiver
from azure.servicebus import ServiceBusMessage
from azure.core.exceptions import ServiceRequestError
import logging

from .base import CloudBenchmark, BenchmarkConfig


class AzureBenchmark(CloudBenchmark):
    """Azure Service Bus benchmark using Docker-based emulator"""

    def __init__(self):
        super().__init__("Azure Service Bus")
        self.service_bus_client = None
        self.connection_string = None
        self.queue_name = None
        self.azurite_container = "azurite-benchmark"
        # Suppress Azure SDK logging for benchmarks
        logging.getLogger('azure.servicebus').setLevel(logging.WARNING)

    async def setup_infrastructure(self, config: BenchmarkConfig) -> bool:
        """Setup Azurite container for Azure Service Bus emulation"""
        try:
            # Note: Using a simple queue implementation since full Service Bus emulator
            # is not available. This simulates the Azure Service Bus API structure.

            # Stop and remove existing container
            await self._run_docker_command([
                "docker", "rm", "-f", self.azurite_container
            ], ignore_errors=True)

            # Start Redis container as message store (simulating Azure Service Bus)
            print("üê≥ Starting Redis container for Azure Service Bus simulation...")
            cmd = [
                "docker", "run", "-d",
                "--name", self.azurite_container,
                "-p", "6380:6379",
                "redis:7-alpine",
                "redis-server", "--appendonly", "yes"
            ]

            if not await self._run_docker_command(cmd):
                return False

            self.docker_containers = [self.azurite_container]

            # Wait for Redis to be ready
            print("‚è≥ Waiting for Redis to be ready...")
            await asyncio.sleep(5)

            # Setup connection string and queue
            self.connection_string = "redis://localhost:6380"
            self.queue_name = config.queue_name

            # Initialize Redis client for simulation
            import redis.asyncio as redis
            self.redis_client = redis.from_url(self.connection_string)

            # Test connection
            for attempt in range(10):
                try:
                    await self.redis_client.ping()
                    print("‚úÖ Azure Service Bus simulation ready!")
                    break
                except Exception as e:
                    if attempt == 9:
                        print(f"‚ùå Redis connection failed: {e}")
                        return False
                    await asyncio.sleep(2)

            print(f"‚úÖ Queue '{self.queue_name}' configured")
            return True

        except Exception as e:
            print(f"‚ùå Failed to setup Azure infrastructure: {e}")
            return False

    async def cleanup_infrastructure(self):
        """Stop and remove Azure emulation container"""
        try:
            print("üßπ Cleaning up Azure infrastructure...")

            # Close Redis client
            if hasattr(self, 'redis_client'):
                await self.redis_client.aclose()

            # Stop container
            if self.azurite_container in self.docker_containers:
                await self._run_docker_command([
                    "docker", "rm", "-f", self.azurite_container
                ], ignore_errors=True)

            print("‚úÖ Azure cleanup completed")
        except Exception as e:
            print(f"‚ö†Ô∏è Azure cleanup error: {e}")

    async def send_messages(self, config: BenchmarkConfig) -> Tuple[int, float, List[float]]:
        """Send messages to Azure Service Bus queue (simulated with Redis)"""
        sent_count = 0
        latencies = []

        # Prepare messages
        messages = []
        for i in range(config.message_count):
            message_data = {
                'id': str(uuid.uuid4()),
                'timestamp': time.time(),
                'sequence': i,
                'data': 'x' * (config.message_size - 100),  # Account for metadata
                'properties': {
                    'ContentType': 'application/json',
                    'MessageId': str(uuid.uuid4()),
                    'TimeToLive': 300  # 5 minutes
                }
            }
            messages.append(message_data)

        # Send messages concurrently
        start_time = time.time()

        async def send_batch(batch_messages, producer_id):
            nonlocal sent_count
            batch_sent = 0

            # Create Redis pipeline for batch operations
            pipe = self.redis_client.pipeline()

            for message_data in batch_messages:
                try:
                    send_start = time.time()

                    # Simulate Service Bus message format
                    service_bus_message = {
                        'body': json.dumps(message_data),
                        'properties': message_data.get('properties', {}),
                        'enqueued_time': time.time(),
                        'sequence_number': message_data['sequence']
                    }

                    # Add to Redis queue (simulating Service Bus queue)
                    queue_key = f"servicebus:queue:{self.queue_name}"
                    pipe.lpush(queue_key, json.dumps(service_bus_message))

                    # Add to batch processing time
                    send_latency = (time.time() - send_start) * 1000
                    latencies.append(send_latency)
                    batch_sent += 1

                except Exception as e:
                    print(f"‚ùå Message preparation error in producer {producer_id}: {e}")

            # Execute batch
            try:
                await pipe.execute()
                sent_count += batch_sent
            except Exception as e:
                print(f"‚ùå Batch send error in producer {producer_id}: {e}")

        # Divide messages among producers
        messages_per_producer = len(messages) // config.concurrent_producers
        producer_tasks = []

        for i in range(config.concurrent_producers):
            start_idx = i * messages_per_producer
            if i == config.concurrent_producers - 1:
                # Last producer gets remaining messages
                batch_messages = messages[start_idx:]
            else:
                end_idx = start_idx + messages_per_producer
                batch_messages = messages[start_idx:end_idx]

            producer_tasks.append(send_batch(batch_messages, i))

        await asyncio.gather(*producer_tasks)

        duration = time.time() - start_time
        return sent_count, duration, latencies

    async def receive_messages(self, config: BenchmarkConfig) -> Tuple[int, float, List[float]]:
        """Receive messages from Azure Service Bus queue (simulated with Redis)"""
        received_count = 0
        latencies = []
        start_time = time.time()

        # Create consumer tasks
        async def consume_messages(consumer_id: int):
            nonlocal received_count
            consumer_received = 0
            target_messages = config.message_count // config.concurrent_consumers

            queue_key = f"servicebus:queue:{self.queue_name}"

            while consumer_received < target_messages:
                try:
                    # Simulate batch receive (Service Bus can receive multiple messages)
                    batch_size = min(config.batch_size, target_messages - consumer_received)

                    receive_start = time.time()

                    # Get messages from Redis (simulating Service Bus receive)
                    pipe = self.redis_client.pipeline()
                    for _ in range(batch_size):
                        pipe.brpop(queue_key, timeout=1)

                    results = await pipe.execute()

                    # Process received messages
                    receipt_time = time.time()

                    for result in results:
                        if result is None:  # Timeout
                            continue

                        try:
                            # Parse Service Bus message
                            _, message_json = result
                            service_bus_message = json.loads(message_json.decode('utf-8'))

                            # Parse original message
                            original_message = json.loads(service_bus_message['body'])
                            send_timestamp = original_message.get('timestamp', receipt_time)

                            # Calculate latency
                            latency = (receipt_time - send_timestamp) * 1000  # Convert to ms
                            latencies.append(latency)

                            consumer_received += 1

                            # Simulate message completion/acknowledgment
                            # In real Service Bus, this would complete the message

                        except Exception as e:
                            print(f"‚ö†Ô∏è Message processing error in consumer {consumer_id}: {e}")

                    if not any(results):
                        await asyncio.sleep(0.1)

                except Exception as e:
                    print(f"‚ùå Consumer {consumer_id} error: {e}")
                    await asyncio.sleep(1)

            received_count += consumer_received

        # Start consumers
        consumer_tasks = [
            consume_messages(i) for i in range(config.concurrent_consumers)
        ]

        # Wait for all consumers to finish or timeout
        try:
            await asyncio.wait_for(
                asyncio.gather(*consumer_tasks),
                timeout=config.timeout
            )
        except asyncio.TimeoutError:
            print("‚ö†Ô∏è Consumer timeout reached")

        duration = time.time() - start_time
        return received_count, duration, latencies

    async def _run_docker_command(self, cmd: List[str], ignore_errors: bool = False) -> bool:
        """Run a Docker command asynchronously"""
        try:
            process = await asyncio.create_subprocess_exec(
                *cmd,
                stdout=asyncio.subprocess.PIPE,
                stderr=asyncio.subprocess.PIPE
            )

            stdout, stderr = await process.communicate()

            if process.returncode != 0 and not ignore_errors:
                print(f"‚ùå Docker command failed: {' '.join(cmd)}")
                print(f"   Error: {stderr.decode()}")
                return False

            return True

        except Exception as e:
            if not ignore_errors:
                print(f"‚ùå Docker command exception: {e}")
            return False


class AzureStorageQueueBenchmark(CloudBenchmark):
    """Azure Storage Queue benchmark using Azurite storage emulator"""

    def __init__(self):
        super().__init__("Azure Storage Queue")
        self.storage_client = None
        self.connection_string = None
        self.queue_name = None
        self.azurite_container = "azurite-storage-benchmark"

    async def setup_infrastructure(self, config: BenchmarkConfig) -> bool:
        """Setup Azurite storage emulator"""
        try:
            # Stop and remove existing container
            await self._run_docker_command([
                "docker", "rm", "-f", self.azurite_container
            ], ignore_errors=True)

            # Start Azurite container
            print("üê≥ Starting Azurite storage emulator...")
            cmd = [
                "docker", "run", "-d",
                "--name", self.azurite_container,
                "-p", "10000:10000",  # Blob service
                "-p", "10001:10001",  # Queue service
                "-p", "10002:10002",  # Table service
                "mcr.microsoft.com/azure-storage/azurite:latest",
                "azurite", "--loose", "--blobHost", "0.0.0.0", "--queueHost", "0.0.0.0"
            ]

            if not await self._run_docker_command(cmd):
                return False

            self.docker_containers = [self.azurite_container]

            # Wait for Azurite to be ready
            print("‚è≥ Waiting for Azurite to be ready...")
            await asyncio.sleep(10)

            # Setup connection string
            self.connection_string = (
                "DefaultEndpointsProtocol=http;"
                "AccountName=devstoreaccount1;"
                "AccountKey=Eby8vdM02xNOcqFlqUwJPLlmEtlCDXJ1OUzFT50uSRZ6IFsuFq2UVErCz4I6tq/K1SZFPTOtr/KBHBeksoGMGw==;"
                "QueueEndpoint=http://127.0.0.1:10001/devstoreaccount1;"
            )

            self.queue_name = config.queue_name.lower().replace('_', '-')  # Azure naming requirements

            # Initialize Azure Storage Queue client
            from azure.storage.queue.aio import QueueServiceClient
            self.storage_client = QueueServiceClient.from_connection_string(self.connection_string)

            # Test connection and create queue
            for attempt in range(15):
                try:
                    await self.storage_client.create_queue(self.queue_name)
                    print("‚úÖ Azure Storage Queue emulator ready!")
                    break
                except Exception as e:
                    if "already exists" in str(e).lower():
                        break
                    if attempt == 14:
                        print(f"‚ùå Azurite connection failed: {e}")
                        return False
                    await asyncio.sleep(2)

            return True

        except Exception as e:
            print(f"‚ùå Failed to setup Azure Storage infrastructure: {e}")
            return False

    async def cleanup_infrastructure(self):
        """Stop and remove Azurite container"""
        try:
            print("üßπ Cleaning up Azure Storage infrastructure...")

            # Close storage client
            if self.storage_client:
                await self.storage_client.close()

            # Stop container
            if self.azurite_container in self.docker_containers:
                await self._run_docker_command([
                    "docker", "rm", "-f", self.azurite_container
                ], ignore_errors=True)

            print("‚úÖ Azure Storage cleanup completed")
        except Exception as e:
            print(f"‚ö†Ô∏è Azure Storage cleanup error: {e}")

    async def send_messages(self, config: BenchmarkConfig) -> Tuple[int, float, List[float]]:
        """Send messages to Azure Storage Queue"""
        sent_count = 0
        latencies = []

        # Get queue client
        queue_client = self.storage_client.get_queue_client(self.queue_name)

        # Prepare messages
        messages = []
        for i in range(config.message_count):
            message_content = json.dumps({
                'id': str(uuid.uuid4()),
                'timestamp': time.time(),
                'sequence': i,
                'data': 'x' * (config.message_size - 100)
            })
            messages.append(message_content)

        # Send messages
        start_time = time.time()

        async def send_batch(batch_messages, producer_id):
            nonlocal sent_count
            batch_sent = 0

            for message_content in batch_messages:
                try:
                    send_start = time.time()

                    await queue_client.send_message(
                        content=message_content,
                        visibility_timeout=None,
                        time_to_live=None
                    )

                    send_latency = (time.time() - send_start) * 1000
                    latencies.append(send_latency)
                    batch_sent += 1

                except Exception as e:
                    print(f"‚ùå Send error in producer {producer_id}: {e}")

            sent_count += batch_sent

        # Execute with concurrency
        messages_per_producer = len(messages) // config.concurrent_producers
        producer_tasks = []

        for i in range(config.concurrent_producers):
            start_idx = i * messages_per_producer
            if i == config.concurrent_producers - 1:
                batch_messages = messages[start_idx:]
            else:
                end_idx = start_idx + messages_per_producer
                batch_messages = messages[start_idx:end_idx]

            producer_tasks.append(send_batch(batch_messages, i))

        await asyncio.gather(*producer_tasks)

        duration = time.time() - start_time
        return sent_count, duration, latencies

    async def receive_messages(self, config: BenchmarkConfig) -> Tuple[int, float, List[float]]:
        """Receive messages from Azure Storage Queue"""
        received_count = 0
        latencies = []
        start_time = time.time()

        # Get queue client
        queue_client = self.storage_client.get_queue_client(self.queue_name)

        async def consume_messages(consumer_id: int):
            nonlocal received_count
            consumer_received = 0
            target_messages = config.message_count // config.concurrent_consumers

            while consumer_received < target_messages:
                try:
                    # Receive messages
                    messages = await queue_client.receive_messages(
                        messages_per_page=min(32, config.batch_size),  # Azure Storage Queue max
                        visibility_timeout=30
                    )

                    receipt_time = time.time()
                    processed_messages = []

                    async for message in messages:
                        try:
                            message_data = json.loads(message.content)
                            send_timestamp = message_data.get('timestamp', receipt_time)
                            latency = (receipt_time - send_timestamp) * 1000
                            latencies.append(latency)

                            processed_messages.append(message)
                            consumer_received += 1

                            if consumer_received >= target_messages:
                                break

                        except Exception as e:
                            print(f"‚ö†Ô∏è Message processing error: {e}")

                    # Delete processed messages
                    for message in processed_messages:
                        try:
                            await queue_client.delete_message(message)
                        except Exception as e:
                            print(f"‚ö†Ô∏è Delete message error: {e}")

                    if not processed_messages:
                        await asyncio.sleep(0.5)

                except Exception as e:
                    print(f"‚ùå Consumer {consumer_id} error: {e}")
                    await asyncio.sleep(1)

            received_count += consumer_received

        # Start consumers
        consumer_tasks = [
            consume_messages(i) for i in range(config.concurrent_consumers)
        ]

        try:
            await asyncio.wait_for(
                asyncio.gather(*consumer_tasks),
                timeout=config.timeout
            )
        except asyncio.TimeoutError:
            print("‚ö†Ô∏è Consumer timeout reached")

        duration = time.time() - start_time
        return received_count, duration, latencies

    async def _run_docker_command(self, cmd: List[str], ignore_errors: bool = False) -> bool:
        """Run a Docker command asynchronously"""
        try:
            process = await asyncio.create_subprocess_exec(
                *cmd,
                stdout=asyncio.subprocess.PIPE,
                stderr=asyncio.subprocess.PIPE
            )

            stdout, stderr = await process.communicate()

            if process.returncode != 0 and not ignore_errors:
                print(f"‚ùå Docker command failed: {' '.join(cmd)}")
                print(f"   Error: {stderr.decode()}")
                return False

            return True

        except Exception as e:
            if not ignore_errors:
                print(f"‚ùå Docker command exception: {e}")
            return False
